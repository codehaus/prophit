
Run the 'hello' target in build.xml to generate java.hprof.txt with 'CPU TIME' data, or look at data/hello.times.txt

The same profile with 'CPU SAMPLES' is in data/hello.hprof.txt. CPU SAMPLES is currently parsed
by java/orbit/parsers/HProfParser.java. The easiest thing to do is probably to enhance it to handle CPU TIME
as well as CPU SAMPLES. It is possible to generate a file with both kinds of data by specifying '-Xrunhprof:cpu=samples,cpu=times'
so we need to figure out what to do in this case. Probably just ignore CPU SAMPLES since CPU TIME is more accurate anyway (actually, looking
at a data file with both, the data is the same for both samples and times).

The entries for CPU TIME and CPU SAMPLES are pretty much the same. Here are both for the util.HelloList profile:

CPU SAMPLES BEGIN (total = 59507) Sun Jul 28 14:03:51 2002
rank   self  accum   count trace method
   1 11.11% 11.11%    6614    85 java.lang.StringBuffer.<init>
   2 11.11% 22.22%    6611    62 java.lang.StringBuffer.<init>
   3  9.68% 31.90%    5758    66 java.lang.StringBuffer.toString
   4  9.52% 41.42%    5667    61 test.HelloList.buildAsStrings

CPU TIME (ms) BEGIN (total = 27249) Tue Aug 20 18:07:32 2002
rank   self  accum   count trace method
   1  5.21%  5.21%   10000   289 util.HelloList.buildAsStrings
   2  5.05% 10.26%   10000   287 util.HelloList.buildAsStrings
   3  3.78% 14.04%  110000   295 java.lang.StringBuffer.toString
   4  3.78% 17.83%  110000   333 java.lang.String.getChars

For CPU SAMPLES, the 'count' is what really matters. Periodically, the profile pauses and samples the current stack; the 'count' field tells you how many times each stack was encountered, so 'count/total' is really the same as the % of time spent in each function.

For CPU TIME, 'count' is less interesting than 'self'. In this case, 'self' is (or should be) the measured amount of time spent in that function as a % of the total running time (encoded in 'total', which is the total running time of the program in milliseconds). 'accum' is not useful to us in either case because we can just compute it.

In both cases, the 'trace' identifies the stack trace which corresponds to the time entry. So 'trace=52' might refer to:

TRACE 52:
	util.HelloList.buildAsStrings(HelloList.java:Unknown line)
	util.HelloList.arrayAndString(HelloList.java:Unknown line)
	util.HelloList.main(HelloList.java:Unknown line)

For CPU SAMPLES, HProfParser uses the traceID to obtain a StackTrace (previously constructed), and uses the 'count' as both the number of invocations ('nCalls') and 'time' arguments to the 'orbit.model.RCC' constructor. This is because there is no actual recording of time when using the sampling method; the time is meant to be inferred from the number of calls to each stack trace. 

For CPU TIME, The 'self' time should be used to determine 'time' argument, and the 'count' should be used as 'nCalls'. The 'time' should actually be computed as totalTime * self / 100.0, because 'self' is the % of the total time spent in 'trace'.

Testing
=======

Testing of the parser package should be in test/java/orbit/parsers. test/java/test/Test.java is some old tests, which includes loading an HProf text file. But shamefully there does not appear to be good testing of the HProfParser class yet. A good test would at least feed in an hprof samples or times file and make sure that certain stack traces have been loaded and that their times make sense. It is tough to test the parsers in a simple way, because even fairly simple programs can create fairly large & complex profile data files.

The best way to create a simple, minimum-bar test would be to hand-write a text file which conforms to the hprof format which encodes only a few simple function calls (see data/simple.prof for a hand-coded example of a simple 'java -prof' data file).
